{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_cleaning_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7XfwZdEKQ0Dm",
        "647R_mwGRzKx",
        "9MCQ7TAdSKn9",
        "TcyqmMgRS8cD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0rQ1yHf7vLC"
      },
      "source": [
        "This notebooks contains some of the frequently used functions in the data cleaning process.\n",
        "\n",
        "1. Check for duplictate rows\n",
        "2. Replace NaN\n",
        "3. Splitting string\n",
        "4. Converting date format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mv2IdgCRl3w"
      },
      "source": [
        "#installing datetime\n",
        "!pip install datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "innqhzPUPrne"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfaZWs7mP46h",
        "outputId": "5523b241-f73d-4216-cb76-712dcf6cc42b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkAB5785QeV0"
      },
      "source": [
        "# For checking duplicate rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbEV-jqoQP4b"
      },
      "source": [
        "#This function checks for duplicate rows and deletes them\n",
        "def duplicate_check(df):\n",
        "  duplicate = df[df.duplicated()]\n",
        "  if duplicate.empty==False:\n",
        "    df=df.drop_duplicates()\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XfwZdEKQ0Dm"
      },
      "source": [
        "# For replacing NaN by 'Not Resolved':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUhtGUv_Q_qy"
      },
      "source": [
        "def not_resolved(df):\n",
        "  df['comp_status'] = df['comp_status'].replace(np.nan, 'Not Resolved')\n",
        "  return df\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "647R_mwGRzKx"
      },
      "source": [
        "# For splitting comp_location into City and State :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhWVLBfqR9Rf"
      },
      "source": [
        "#Splitting done on basis of ','\n",
        "def location(df):\n",
        "  df[['City','State']] = df.comp_location.str.split(\",\",1,expand=True)\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MCQ7TAdSKn9"
      },
      "source": [
        "# For splitting compl_title into Company Name and Title:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0m2120vSRav"
      },
      "source": [
        "#Splitting done on basis of '\\n'\n",
        "def name_title_split(df,):\n",
        "  df[['Comp Name','title']] = df.compl_title.str.split(\"\\n\",1,expand=True)\n",
        "  df['Company Name'] = df['Comp Name'].str[:-1]\n",
        "  #df=df.drop(['Comp Name'], axis = 1)\n",
        "  return df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcyqmMgRS8cD"
      },
      "source": [
        "# For converting into date format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue_aiR0Oa7Y2"
      },
      "source": [
        "def convert_date(d):\n",
        "  months_dict={'Jan':'01', 'Feb':'02', 'Mar':'03', 'Apr':'04', 'May':'05', 'Jun':'06', 'Jul':'07', 'Aug':'08', 'Sep':'09', 'Oct':'10', 'Nov':'11', 'Dec':'12'}\n",
        "  a=str(d)\n",
        "  mylist=a.split()\n",
        "  if len(mylist)==3:\n",
        "    mm=mylist[0]\n",
        "    dd=mylist[1]\n",
        "    yyyy=mylist[2]\n",
        "    dd=dd[:-1]\n",
        "    mm=months_dict[mm]\n",
        "    final_date=dd+'-'+mm+'-'+yyyy\n",
        "    return final_date\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7o3Kzebh-H6"
      },
      "source": [
        "# All Functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKdbxXeciHUk"
      },
      "source": [
        "def cleaning_dataset(filename):\n",
        "  try:\n",
        "    path =\"/content/drive/MyDrive/\"+filename\n",
        "    df=pd.read_csv(path)\n",
        "    duplicate_check(df)\n",
        "    not_resolved(df)\n",
        "    location(df)\n",
        "    name_title_split(df)\n",
        "    df=df.drop(['Comp Name'], axis = 1)\n",
        "    df['complaint_date_changed'] = df.apply(lambda row : convert_date(row['comp_date']), axis = 1)\n",
        "    df['complaint_date_changed'] = pd.to_datetime(df.complaint_date_changed)\n",
        "    df['complaint_date_changed'] = df['complaint_date_changed'].dt.strftime('%d-%m-%Y')\n",
        "    df['Update_date_changed'] = df.apply(lambda row : convert_date(row['update_date']), axis = 1)\n",
        "    df['Update_date_changed'] = pd.to_datetime(df.Update_date_changed)\n",
        "    df['Update_date_changed'] = df['Update_date_changed'].dt.strftime('%d-%m-%Y')\n",
        "    msg=\"Data cleaning successful\"\n",
        "  except:\n",
        "    msg=\"File not found on Drive\"\n",
        "    return df,msg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0YCI3-tjjbR"
      },
      "source": [
        "df=cleaning_dataset('merge_file.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOnfX05UYvpL"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}